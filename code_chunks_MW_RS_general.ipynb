{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86da0a78-0caf-48ce-a740-675ea4f0a54c",
   "metadata": {},
   "source": [
    "# Code chunks for Exercise 1\n",
    "\n",
    "Welcome to this Jupyter notebook collecting many code chunks that are useful for the MRS UE exercises. It presents typical Python tools for working with geo data, as also used in professional remote sensing. A focus is put on the first exercise, i.e. classifying forests with optical imagery.\n",
    "\n",
    "## Some Python libraries you might need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe4458-8bb4-424f-a0f9-ad774955fbff",
   "metadata": {
    "tags": []
   },
   "source": [
    "A lot of libraries will be used for the exercise, but don't get intimidated by the amout of imports. They mostly fulfill small tasks. \n",
    "\n",
    "First, we import some popular, useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca37e48-0481-4b21-930e-0335e5bba19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xar\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e77d6a-8d2a-4314-a819-e61a22692aa4",
   "metadata": {},
   "source": [
    "Then, we continue with in-house production software for all sorts of data processing. For more information have a look at https://github.com/TUW-GEO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1537ab-1867-47bf-ab85-0355de679add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geospade.crs import SpatialRef\n",
    "from veranda.io.geotiff import write_tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7571779-b339-4aba-82b2-72b9732bd505",
   "metadata": {},
   "source": [
    "Several tasks cannot be solely managed with the existing general-purpose packages. Therefore, we have created a helper package dedicated for this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245bf0ef-cec5-428c-b00d-6b6162f2c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afe.add_ons import generate_tree\n",
    "from afe.add_ons import OpticalDataCube\n",
    "from afe.geometry import PolygonCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6e614-060d-4798-856f-1353de17774a",
   "metadata": {},
   "source": [
    "Next, we import the `scikit-learn` machine learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc86ab-c854-45bc-9c5b-f820362c88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3297b8-8f7a-4d0c-adbc-62353362403a",
   "metadata": {},
   "source": [
    "Now, we import `matplotlib` for interactive plots and `roi` to draw polygons and export them as geojson files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff4464-497f-4ea5-b69d-c33ed8d1ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from ipywidgets import widgets, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075d6a3-0260-4f51-b0f9-26c69bd2c21a",
   "metadata": {},
   "source": [
    "Finally, we import our own python scripts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc40238-7ba8-4d77-b6fb-942d0ac728a9",
   "metadata": {},
   "source": [
    "and activate its `widget` backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd4388-470d-4240-bdd4-e5f4b3dcc661",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget  \n",
    "%matplotlib widget "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a338b4b-96bb-443e-ac5a-43f75bc2fe6c",
   "metadata": {},
   "source": [
    "It is generally a good idea to run these widget-commands twice to avoid issues when changing the backend (https://matplotlib.org/2.0.2/faq/usage_faq.html#what-is-a-backend)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89233b84-3095-44b6-ad2f-9c25901b48cc",
   "metadata": {},
   "source": [
    "To allow for running the code chunks for any user, we can globally define our username here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342829d-1e49-4c63-95ed-e4f268f4d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = os.getcwd().split('/')[2] #This command should automatically get your username\n",
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514169a7-294a-402e-b9f6-9a1da0e108e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afe.contrast import auto_clip, clip, stretch\n",
    "from afe.imagechoice import quicklook, display_extent\n",
    "from afe.roi import roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d97975-255d-4c66-8eed-acc445acf4c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imagesearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415d110-2400-44d7-9fc2-e4807f90e238",
   "metadata": {},
   "source": [
    "Since Jupyterhub does not display the QTCI images and for easier identification of the quality of your image, you can use the python script shown in the following cells.\n",
    "In the first step, we have to establish the path, which leads us to the available tiles. Next we use the function `quicklook`, the parameters `tile` and `img`  should be empty at first, so that we can choose the tile and later the image. The function will ask you for an input, aslong asat least on of the parameters is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe04d1ed-41e6-4387-9baa-1d5e15db4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = f'/home/{USER}/shared/datasets/fe/data/'\n",
    "rootpath = gen_path + f'sentinel2/L2A/EU010M'\n",
    "image = quicklook(rootpath, tile='', img='', figsize=(9,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5196fb-b76e-4d49-b3ac-4a0dcc3fcf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = quicklook(rootpath, tile='5', img='106', figsize=(9,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39f6e5-3b4b-4abd-a3d1-ef7b73e07912",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_col, ul_row = 9000,2800  \n",
    "col_size, row_size = 800, 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9b052-5136-41d6-a8a2-9416aedb2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_extent(image, ul_col=ul_col, ul_row=ul_row, col_size=col_size, row_size=row_size, title='Sub Area')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb402ce-1c30-41e7-8e6a-6e813efe93fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749ab1c-5c39-4f70-901c-0c2b3a4af3d2",
   "metadata": {},
   "source": [
    "The loaded data is in a structure called `xarray` there are many ways to manipulate a data array and get information out of it. For this example we will create a simple 2D xarray with the coordinates `cities` and `time` and temperature regarding variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0294987-d509-4dd7-a380-9b2e2acb1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(\"2014-09-06\", periods=3)\n",
    "cities = [\"Munich\", \"Vienna\", \"Berlin\", \"London\", \"Rome\"]\n",
    "\n",
    "max_temps = np.random.uniform(low=25, high=38, size=(5, 3))\n",
    "avg_temps = np.random.uniform(low=20, high=30, size=(5, 3))\n",
    "min_temps = np.random.uniform(low=15, high=25, size=(5, 3))\n",
    "humidity = np.random.uniform(low=15, high=100, size=(5, 3))\n",
    "\n",
    "temp_ds = xar.Dataset(\n",
    "    coords={\n",
    "        \"city\": cities,\n",
    "        \"time\": times,\n",
    "    },\n",
    "    data_vars={\n",
    "        \"min_temperature\": ([\"city\", \"time\"], min_temps),\n",
    "        \"avg_temperature\": ([\"city\", \"time\"], avg_temps),\n",
    "        \"max_temperature\": ([\"city\", \"time\"], max_temps),\n",
    "        \"humidity\": ([\"city\", \"time\"], humidity)\n",
    "    }\n",
    ")\n",
    "temp_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed31bb-1c08-423d-ade5-e46a1c6eec64",
   "metadata": {},
   "source": [
    "We can define a new xarray dataset `temps_mean`: `dim` specifies the dimension to apply the mean along. `skipna` is used to signal that NaN (Not-a-Number) values should be ignored. Keep this in mind, you will have to use `skipna` in combination with another function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bbfb3-79be-4b9c-bd5e-47b4cb217cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_mean = temp_ds.mean(dim=\"time\", skipna=False)\n",
    "temps_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d40e3-ae79-443b-8a02-38030810e271",
   "metadata": {},
   "source": [
    "We can also extract the values of a single variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c3824-3a29-4cb9-9331-c36ae96d7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_temps = temps_mean['min_temperature']\n",
    "min_temps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4060bc-e57e-427f-a443-88bd6ee5ba38",
   "metadata": {},
   "source": [
    "xarray extensively uses the popular `numpy` library in its background.\n",
    "\n",
    "In case you want to extract a `numpy` array from your `xarray` data, which is sometimes needed, you can do that by:\n",
    "1. (optional) converting your `xarray.Dataset` to `xarray.DataArray` by calling `to_array()` , which removes your data variables but keeps all your data in an n-dimensional array.\n",
    "2. accessing your `xarray.DataArray`'s `values` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a664306-d5cb-4b8d-b7c8-04e3e8c5e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_mean.to_array().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb6d96d-20a5-4610-a51f-0413aa3b6c1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2698e-722c-4035-988b-ef1fe8e66de0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7d34b-1942-4498-87e7-0441a914dd7d",
   "metadata": {},
   "source": [
    "With the xarray created by loading the Sentinel 2 data we cannot just yet create a meaningful image. As we have already seen in the loaded xarray we have nine different bands available for each time, x and y-coordinate.\n",
    "- B02: Blue\n",
    "- B03: Green\n",
    "- B04: Red\n",
    "- B05: Vegetation red edge\n",
    "- B06: Vegetation red edge \n",
    "- B07: Vegetation red edge \n",
    "- B08: NIR\n",
    "- B11: SWIR\n",
    "- B12: SWIR \n",
    "\n",
    "We have to extract the bands we need from our xarray in order to create an rgb-image. To do this we have to stack the concerned bands with the function `np.stack`. In the following cells the stacking of the images is explained with a simple example, so that you understand it better. \n",
    "\n",
    "First we create a 4 by 4 pixelgrid with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3a7e9-eac9-4070-af49-f63a18ad14d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pixel =4\n",
    "y_pixel =4\n",
    "\n",
    "#R Values\n",
    "r_val = np.round(np.random.rand(x_pixel,y_pixel),2)\n",
    "r_val[0,0]=0\n",
    "r_val[x_pixel-1,y_pixel-1]=1\n",
    "\n",
    "#G Values\n",
    "g_val = np.round(np.random.rand(x_pixel,y_pixel),2)\n",
    "g_val[0,0]=0\n",
    "g_val[x_pixel-1,y_pixel-1]=1\n",
    "\n",
    "#B Values\n",
    "b_val = np.round(np.random.rand(x_pixel,y_pixel),2)\n",
    "b_val[0,0]=0\n",
    "b_val[x_pixel-1,y_pixel-1]=1\n",
    "\n",
    "#Stacked arrays at different axis\n",
    "rgb_ax2 = np.stack([r_val, g_val, b_val], axis=2)\n",
    "rgb_ax0 = np.stack([r_val, g_val, b_val], axis=0)\n",
    "rgb_ax1 = np.stack([r_val, g_val, b_val], axis=1)\n",
    "\n",
    "\n",
    "print('Shape of R,G,B Values (x,y):',r_val.shape)\n",
    "print('Shape of RGB stacke on axis=2: (x,y,z)=',rgb_ax2.shape)\n",
    "print('Shape of RGB stacke on axis=1: (x,z,y)=',rgb_ax1.shape)\n",
    "print('Shape of RGB stacke on axis=0: (z,x,y)=',rgb_ax0.shape)\n",
    "print('Images stacked at axis 0 or 1 are not plottable! Except in some cases when x and y is the same.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909543bf-0bf1-4be1-bb83-62b7459a602b",
   "metadata": {},
   "source": [
    "Now we plot the RGB values separately and stack them along different axis. As you can see the stacke array along axis = 0 is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708e0da-499f-4bb8-b30d-7b9b11593a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(8,7))\n",
    "ax[0,0].imshow(r_val, cmap='Reds_r')\n",
    "ax[0,1].imshow(g_val, cmap='Greens_r')\n",
    "ax[0,2].imshow(b_val, cmap='Blues_r')\n",
    "\n",
    "ax[1,0].imshow(rgb_ax2)\n",
    "ax[1,1].imshow(rgb_ax1)\n",
    "ax[1,2].imshow(rgb_ax0)\n",
    "\n",
    "\n",
    "ax[0,0].set_title('R Values')\n",
    "ax[0,1].set_title('G Values')\n",
    "ax[0,2].set_title('B Values')\n",
    "ax[1,0].set_title('RGB Values\\nStacked axis = 2')\n",
    "ax[1,1].set_title('RGB Values\\nStacked axis = 1')\n",
    "ax[1,2].set_title('RGB Values\\nStacked axis = 0')\n",
    "\n",
    "fig.suptitle('Random RGB Values\\n Note: upper left corner is always 0 and lower right corner is 1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654c571-2e01-4909-a179-587a9e1ec862",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e0d2a-6dee-4457-ab6f-63b43dca3772",
   "metadata": {},
   "source": [
    "It is very helpful creating a histogram for your images. A histogram shows the distribution of your pixel values in regards to their color intenensity, meaning low intensities bring dark pixels (black=0) and high intensities bright pixels (white=1).\n",
    "\n",
    "To create a histogram you can use the `hist()` function. Be careful as it only accepts one dimensional arrays. The dimension of an array can be reduced using the `flatten()` function. As we want to show the distribution for each band seperately we have to extract the bands from the rgb-image first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d3eee2-d290-4205-8f47-1409ee230d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rgb_histogram(rgb_im, ax, title, bins = 300):\n",
    "    mbins = np.linspace(np.nanmin(rgb_im), np.nanmax(rgb_im), bins)\n",
    "    ax.hist(rgb_im[:, :, 2].flatten(), color='blue', bins=mbins,  alpha=0.5)\n",
    "    ax.hist(rgb_im[:, :, 1].flatten(), color='green', bins=mbins,  alpha=0.5)\n",
    "    ax.hist(rgb_im[:, :, 0].flatten(), color='red', bins=mbins, alpha=0.5)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('I')\n",
    "    ax.set_ylabel('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b894f5d-8f16-4ccc-9c4d-c31210b2458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "plot_rgb_histogram(rgb_ax2, ax[1], 'Histogram of raw RGB channels', bins=20)\n",
    "ax[0].imshow(rgb_ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6f5a89-260f-4eb6-b11e-c6454593275b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clip and increase contrast of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152935b-5d2a-41da-a65c-4937ae18918e",
   "metadata": {},
   "source": [
    "To fix this problem we can increase the contrast of the image. To do this we implement the following functions, which will be needed for processing your image. For more details on how these functions work and why we need them to increase contrast and correctly encode the data, take a look at https://www.cg.tuwien.ac.at/courses/EinfVisComp/Skriptum/SS13/EVC-11%20Point%20Operations.pdf for a great overview.\n",
    "\n",
    "The Contrast functions are explained in more detail in the other code chunks. Here the functions are only imported and not directly defined.\n",
    "\n",
    "\n",
    "First we load an random image for exemplary use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84338a21-473f-4d20-8ba1-bd42583aaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = f'/home/{USER}/shared/datasets/fe/data/'\n",
    "root_dirpath = gen_path + f'sentinel2/L2A'\n",
    "dir_tree = generate_tree(root_dirpath)\n",
    "filepaths = dir_tree.file_register\n",
    "dc = OpticalDataCube(filepaths=filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a328ec-a58e-45a5-9132-0bb2cfebaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Parameter\n",
    "Tile = 'E052N016T1'\n",
    "Spectral_band = dc.SPECTRAL_BANDS[0:3]\n",
    "Date = datetime.date(2018,5,6)\n",
    "\n",
    "delta = 10\n",
    "Date_tuple = (Date - datetime.timedelta(days=delta), Date + datetime.timedelta(days=delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab2585-fd87-4863-b4f1-c2e6dc2fa025",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.filter_spatially_by_tilename(Tile, inplace=True)\n",
    "dc.filter_by_dimension(Spectral_band, name=\"var_name\", inplace=True)\n",
    "dc.filter_by_dimension([Date_tuple], expressions=[('>=','<=')], name='time', inplace=True)\n",
    "dc.inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b02a6-b93f-4861-a9cb-b636820c0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_col, ul_row = 9000,2800  \n",
    "col_size, row_size = 800, 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461e2b0-ff6b-4232-ae11-c59d5328848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = dc.load_available_bands_by_pixels(ul_col, ul_row, col_size, row_size)\n",
    "single_image = loaded_data.sel(time=Date)\n",
    "single_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb5fe2-0e14-40bd-a34a-fd21ddb30f73",
   "metadata": {},
   "source": [
    "We have now filtered the Datacube for our likeing and we are going to load the RGB Values and stack them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e11539-a171-4236-b744-a2abf721f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b02 = single_image['B02'].values\n",
    "b03 = single_image['B03'].values\n",
    "b04 = single_image['B04'].values\n",
    "rgb_raw = np.stack([b04, b03, b02], axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937da50-6f48-481d-8684-285bd48a3785",
   "metadata": {},
   "source": [
    "Now we plot the image and its Histogram. as you can see the contrast in the image is terrible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7804b4b-e1d0-4c28-9acc-7c5508fda337",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(11,5))\n",
    "plot_rgb_histogram(rgb_raw, ax[1], 'Histogram of raw RGB channels', bins=300)\n",
    "\n",
    "ax[0].imshow(rgb_raw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dbd9b1-9fe5-4ddd-b71b-e0cd8e3fa8bc",
   "metadata": {},
   "source": [
    "Now we clip the data, inorder to increase the contrast. Sets all values in I that are outside of [v_min, v_max] to the corresponding boundary, in this case defined by the percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd4d1e-000f-41cc-a197-e510a791b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_clipped = auto_clip(rgb_raw.copy(), percentile=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a42e52-6b52-4a3a-992d-76e3b12475c9",
   "metadata": {},
   "source": [
    "We can create a histogram with the clipped data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ab5ac-14e5-46b3-97f9-30296b7fa95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "plot_rgb_histogram(rgb_clipped, ax[1], 'Histogram of clipped RGB channels')\n",
    "ax[0].imshow(rgb_clipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ecc2e-01e6-4a3a-be34-2938ada6dde9",
   "metadata": {},
   "source": [
    "You can see that the histogram now has clear borders, and all the values below/above these borders have been set to the border values. You can play around clipping fewer/more values by setting the percentile value in the `auto_clip()` function. The `pooled` parameter sets if the bands get clipped individually (`=FALSE`) or as a group (`=TRUE`).\n",
    "\n",
    "As the intensity of the values is still too low after clipping we have to stretch the values to spread between 0 and 1. We can do this by using the `stretch()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c39a1c-ce8d-4a59-88ca-42a008dc6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_clipped_stretched = stretch(rgb_clipped, 0, 1, pooled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61d812-05ec-4772-b3bf-368b8e7e3d25",
   "metadata": {},
   "source": [
    "Lets show the final results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc0b58-484a-41c4-8736-64af182fcffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "plot_rgb_histogram(rgb_clipped_stretched, ax[1], 'Histogram of raw RGB channels')\n",
    "ax[0].imshow(rgb_clipped_stretched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50aa18-8aa0-4b72-8045-cda04883e312",
   "metadata": {},
   "source": [
    "If the final image still has a too low contrast you can try increasing the `percentile` parameter in the `auto_clip` function or try using the `np.log` function on the raw image before clipping and stretching it.\n",
    "\n",
    "You can see what happens when we play around with the `percentile` parameter in the `auto_clip` function or use the `np.log` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94fb39-bdbe-41ef-aebd-a92e4750d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_clipped_stretched_01 = stretch(auto_clip(rgb_raw.copy(), percentile=0.01),0,1)\n",
    "rgb_clipped_stretched_05 = stretch(auto_clip(rgb_raw.copy(), percentile=0.05),0,1)\n",
    "rgb_clipped_stretched_15 = stretch(auto_clip(rgb_raw.copy(), percentile=0.15),0,1)\n",
    "rgb_clipped_stretched_log = stretch(auto_clip(np.log(rgb_raw.copy()), percentile=0.05),0,1)\n",
    "\n",
    "fig,ax = plt.subplots(2,2,figsize=(10,10))\n",
    "ax[0,0].imshow(rgb_clipped_stretched_01)\n",
    "ax[0,0].set_title(\"percentile = 0.01\")\n",
    "ax[0,1].imshow(rgb_clipped_stretched_05)\n",
    "ax[0,1].set_title(\"percentile = 0.05\")\n",
    "ax[1,0].imshow(rgb_clipped_stretched_15)\n",
    "ax[1,0].set_title(\"percentile = 0.15\")\n",
    "ax[1,1].imshow(rgb_clipped_stretched_log)\n",
    "ax[1,1].set_title(\"log and percentile = 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a62a10-fcad-4962-94ed-b636d6c8b0f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculating NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48d822-7926-4871-bbbb-3d86392cf6fb",
   "metadata": {},
   "source": [
    "NDVI and many other indices rely on the normalized difference, represented by the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c81da1-5abe-4ae0-b773-4067b9ac71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_difference(a, b):\n",
    "    return (a - b) / (a + b)\n",
    "\n",
    "def ndvi(xar_data):\n",
    "    return normalized_difference(xar_data['<band A>'], xar_data['<band B>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa4ce8-2fb9-4c00-99f0-87b85260fedc",
   "metadata": {},
   "source": [
    "The `ndvi` function takes an `xarray.Dataset` where both `'<band A>'` and `'<band B>'` are data variables and returns an `xarray.DataArray` for the resulting NDVI. Note, that `'<band A>'` and `'<band B>'` are only placeholders. Think about which bands have to be used for computing the NDVI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c104fed-3af8-44c8-ac5d-72f030f553df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating logical matrices\n",
    "\n",
    "Generate random 100x100 matrix filled with values from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a09dba-137f-4c2a-94ab-363d5f194f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mat = np.random.rand(100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb34598a-76fa-4cab-a88c-b17dfe3b779b",
   "metadata": {},
   "source": [
    "Create a logical matrix with the same dimensions as `rand_mat`, where values greater than 0.7 are assigned `True`, the rest is `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b3e68-957e-4338-bf41-b6c1082ac778",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mat = (rand_mat > 0.7)\n",
    "log_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b2e4d-905a-4968-a297-07bf3f11481d",
   "metadata": {},
   "source": [
    "Such a logical matrix can then be applied to mask values in a fashionable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920024b-7288-4d8f-aaeb-c79cdd52778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "42 * True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b21110-d35d-45ee-b9f3-b3728045172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "123 * False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f5896-1038-4d09-97ac-653058f36801",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1, 2], [3, 4]]) * np.array([[True, False], [False, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ec996-d26d-406d-9200-0d7196a41393",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mat * log_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd4183-3dfa-4295-89b6-f5e07cae198c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afe23w",
   "language": "python",
   "name": "afe23w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
